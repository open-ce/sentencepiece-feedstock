{% set version = "0.1.97" %}
{% set name = "sentencepiece" %}

package:
   name: {{ name|lower }}
   version: {{ version }}

source:
  git_url: https://github.com/google/sentencepiece
  git_rev: v{{ version }}

build:
  number: 1
  string: h{{ PKG_HASH }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }}
  script_env:
    - GCC_11_HOME                        #[ppc_arch == 'p10']

requirements:
  build:
    - cmake {{ cmake }} 
    - make
    - {{ compiler('cxx') }}              #[ppc_arch != "p10"]
    - pkg-config {{ pkg_config }}
  host:
    - python {{ python }}
    - setuptools {{ setuptools }}
    - protobuf {{ protobuf }}
    - patchelf 0.12
  run:
    - python {{ python }} 
    - protobuf {{ protobuf }}

test:
  imports:
    - sentencepiece
  requires:
    - pip
    - pytest
  source_files:
    - python/test
    - data
  commands:
    # upstream test suite expects to be run from PKG_ROOT/python
    - cd python && pytest test

about:
  home: https://github.com/google/sentencepiece
  license: Apache License 2.0
  license_family: Apache
  license_file: 'LICENSE'
  summary: "An unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems."
  description: |
      SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation 
      systems where the vocabulary size is predetermined prior to the neural model training. SentencePiece implements 
      subword units (e.g., byte-pair-encoding (BPE) [Sennrich et al.]) and unigram language model [Kudo.]) with the 
      extension of direct training from raw sentences. SentencePiece allows us to make a purely end-to-end system that
      does not depend on language-specific pre/postprocessing.
  dev_url: https://github.com/google/sentencepiece
  doc_url: https://github.com/google/sentencepiece

extra:
  recipe-maintainers:
    - open-ce/open-ce-dev-team
