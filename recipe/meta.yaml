{% set version = "0.1.91" %}
{% set name = "sentencepiece" %}

package:
   name: {{ name|lower }}
   version: {{ version }}

source:
  git_url: https://github.com/google/sentencepiece
  git_rev: v{{ version }}
  patches:
    # 03xx - patch temporary to fix a problem that when fixed upstream can be removed
    - 0300-fix-incompatible-protobuf-headers-error.patch

build:
  number: 6
  string: h{{ PKG_HASH }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }}

requirements:
  build:
    - cmake {{ cmake }} 
    - make
    - {{ compiler('cxx') }}
    - pkg-config {{ pkg_config }}
    - patch
    # Use pins to control cos6/cos7 match
    - libgcc-ng  {{ libgcc }}
    - libstdcxx-ng  {{ libstdcxx }}
  host:
    - python {{ python }}
    - setuptools {{ setuptools }}
    - protobuf {{ protobuf }}
    - patchelf
    # Use pins to control cos6/cos7 match
    - libgcc-ng  {{ libgcc }}
    - libstdcxx-ng  {{ libstdcxx }}
  run:
    - python {{ python }} 
    - protobuf {{ protobuf }}

test:
  imports:
    - sentencepiece
 
about:
  home: https://github.com/google/sentencepiece
  license: Apache License 2.0
  license_family: Apache
  license_file: 'LICENSE'
  summary: "An unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems."
  description: |
      SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation 
      systems where the vocabulary size is predetermined prior to the neural model training. SentencePiece implements 
      subword units (e.g., byte-pair-encoding (BPE) [Sennrich et al.]) and unigram language model [Kudo.]) with the 
      extension of direct training from raw sentences. SentencePiece allows us to make a purely end-to-end system that
      does not depend on language-specific pre/postprocessing.
  dev_url: https://github.com/google/sentencepiece
  doc_url: https://github.com/google/sentencepiece

extra:
  recipe-maintainers:
    - open-ce/open-ce-dev-team
